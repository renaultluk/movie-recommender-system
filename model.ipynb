{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataframe\n",
    "##### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>title</th>\n",
       "      <th>Netflix</th>\n",
       "      <th>Hulu</th>\n",
       "      <th>Prime Video</th>\n",
       "      <th>Disney+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10194.0</td>\n",
       "      <td>[16, 35, 10751]</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>81.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[12, 14, 10751]</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>104.0</td>\n",
       "      <td>['en', 'fr']</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119050.0</td>\n",
       "      <td>[10749, 35]</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>101.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 18, 10749]</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>127.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96871.0</td>\n",
       "      <td>[35]</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>106.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 80, 18, 53]</td>\n",
       "      <td>tt0113277</td>\n",
       "      <td>en</td>\n",
       "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>170.0</td>\n",
       "      <td>['en', 'es']</td>\n",
       "      <td>Heat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 10749]</td>\n",
       "      <td>tt0114319</td>\n",
       "      <td>en</td>\n",
       "      <td>An ugly duckling having undergone a remarkable...</td>\n",
       "      <td>['DE', 'US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>127.0</td>\n",
       "      <td>['fr', 'en']</td>\n",
       "      <td>Sabrina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 12, 18, 10751]</td>\n",
       "      <td>tt0112302</td>\n",
       "      <td>en</td>\n",
       "      <td>A mischievous young boy, Tom Sawyer, witnesses...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>97.0</td>\n",
       "      <td>['en', 'de']</td>\n",
       "      <td>Tom and Huck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 12, 53]</td>\n",
       "      <td>tt0114576</td>\n",
       "      <td>en</td>\n",
       "      <td>International action superstar Jean Claude Van...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>106.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Sudden Death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>645.0</td>\n",
       "      <td>[12, 28, 53]</td>\n",
       "      <td>tt0113189</td>\n",
       "      <td>en</td>\n",
       "      <td>James Bond must unmask the mysterious head of ...</td>\n",
       "      <td>['GB', 'US']</td>\n",
       "      <td>1995-11-16</td>\n",
       "      <td>130.0</td>\n",
       "      <td>['en', 'ru', 'es']</td>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   belongs_to_collection               genres    imdb_id original_language  \\\n",
       "0                10194.0      [16, 35, 10751]  tt0114709                en   \n",
       "1                    NaN      [12, 14, 10751]  tt0113497                en   \n",
       "2               119050.0          [10749, 35]  tt0113228                en   \n",
       "3                    NaN      [35, 18, 10749]  tt0114885                en   \n",
       "4                96871.0                 [35]  tt0113041                en   \n",
       "5                    NaN     [28, 80, 18, 53]  tt0113277                en   \n",
       "6                    NaN          [35, 10749]  tt0114319                en   \n",
       "7                    NaN  [28, 12, 18, 10751]  tt0112302                en   \n",
       "8                    NaN         [28, 12, 53]  tt0114576                en   \n",
       "9                  645.0         [12, 28, 53]  tt0113189                en   \n",
       "\n",
       "                                            overview production_countries  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...               ['US']   \n",
       "1  When siblings Judy and Peter discover an encha...               ['US']   \n",
       "2  A family wedding reignites the ancient feud be...               ['US']   \n",
       "3  Cheated on, mistreated and stepped on, the wom...               ['US']   \n",
       "4  Just when George Banks has recovered from his ...               ['US']   \n",
       "5  Obsessive master thief, Neil McCauley leads a ...               ['US']   \n",
       "6  An ugly duckling having undergone a remarkable...         ['DE', 'US']   \n",
       "7  A mischievous young boy, Tom Sawyer, witnesses...               ['US']   \n",
       "8  International action superstar Jean Claude Van...               ['US']   \n",
       "9  James Bond must unmask the mysterious head of ...         ['GB', 'US']   \n",
       "\n",
       "  release_date  runtime    spoken_languages                        title  \\\n",
       "0   1995-10-30     81.0              ['en']                    Toy Story   \n",
       "1   1995-12-15    104.0        ['en', 'fr']                      Jumanji   \n",
       "2   1995-12-22    101.0              ['en']             Grumpier Old Men   \n",
       "3   1995-12-22    127.0              ['en']            Waiting to Exhale   \n",
       "4   1995-02-10    106.0              ['en']  Father of the Bride Part II   \n",
       "5   1995-12-15    170.0        ['en', 'es']                         Heat   \n",
       "6   1995-12-15    127.0        ['fr', 'en']                      Sabrina   \n",
       "7   1995-12-22     97.0        ['en', 'de']                 Tom and Huck   \n",
       "8   1995-12-22    106.0              ['en']                 Sudden Death   \n",
       "9   1995-11-16    130.0  ['en', 'ru', 'es']                    GoldenEye   \n",
       "\n",
       "   Netflix  Hulu  Prime Video  Disney+  \n",
       "0      NaN   NaN          NaN      NaN  \n",
       "1      NaN   NaN          NaN      NaN  \n",
       "2      NaN   NaN          NaN      NaN  \n",
       "3      NaN   NaN          NaN      NaN  \n",
       "4      NaN   NaN          NaN      NaN  \n",
       "5      NaN   NaN          NaN      NaN  \n",
       "6      NaN   NaN          NaN      NaN  \n",
       "7      0.0   0.0          0.0      1.0  \n",
       "8      NaN   NaN          NaN      NaN  \n",
       "9      NaN   NaN          NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"meta_clean.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 44413 entries, tt0114709 to tt6980792\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   belongs_to_collection  4427 non-null   float64\n",
      " 1   genres                 44413 non-null  object \n",
      " 2   original_language      44413 non-null  object \n",
      " 3   overview               44413 non-null  object \n",
      " 4   production_countries   44413 non-null  object \n",
      " 5   release_date           44413 non-null  object \n",
      " 6   runtime                44413 non-null  float64\n",
      " 7   spoken_languages       44413 non-null  object \n",
      " 8   title                  44413 non-null  object \n",
      " 9   Netflix                2205 non-null   float64\n",
      " 10  Hulu                   2205 non-null   float64\n",
      " 11  Prime Video            2205 non-null   float64\n",
      " 12  Disney+                2205 non-null   float64\n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 4.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>genres</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>title</th>\n",
       "      <th>Netflix</th>\n",
       "      <th>Hulu</th>\n",
       "      <th>Prime Video</th>\n",
       "      <th>Disney+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tt0114709</th>\n",
       "      <td>10194.0</td>\n",
       "      <td>[16, 35, 10751]</td>\n",
       "      <td>en</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>81.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[12, 14, 10751]</td>\n",
       "      <td>en</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>104.0</td>\n",
       "      <td>['en', 'fr']</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113228</th>\n",
       "      <td>119050.0</td>\n",
       "      <td>[10749, 35]</td>\n",
       "      <td>en</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>101.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0114885</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 18, 10749]</td>\n",
       "      <td>en</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>127.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113041</th>\n",
       "      <td>96871.0</td>\n",
       "      <td>[35]</td>\n",
       "      <td>en</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>106.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113277</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 80, 18, 53]</td>\n",
       "      <td>en</td>\n",
       "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>170.0</td>\n",
       "      <td>['en', 'es']</td>\n",
       "      <td>Heat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0114319</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 10749]</td>\n",
       "      <td>en</td>\n",
       "      <td>An ugly duckling having undergone a remarkable...</td>\n",
       "      <td>['DE', 'US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>127.0</td>\n",
       "      <td>['fr', 'en']</td>\n",
       "      <td>Sabrina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0112302</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 12, 18, 10751]</td>\n",
       "      <td>en</td>\n",
       "      <td>A mischievous young boy, Tom Sawyer, witnesses...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>97.0</td>\n",
       "      <td>['en', 'de']</td>\n",
       "      <td>Tom and Huck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0114576</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 12, 53]</td>\n",
       "      <td>en</td>\n",
       "      <td>International action superstar Jean Claude Van...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>106.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Sudden Death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113189</th>\n",
       "      <td>645.0</td>\n",
       "      <td>[12, 28, 53]</td>\n",
       "      <td>en</td>\n",
       "      <td>James Bond must unmask the mysterious head of ...</td>\n",
       "      <td>['GB', 'US']</td>\n",
       "      <td>1995-11-16</td>\n",
       "      <td>130.0</td>\n",
       "      <td>['en', 'ru', 'es']</td>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           belongs_to_collection               genres original_language  \\\n",
       "imdb_id                                                                   \n",
       "tt0114709                10194.0      [16, 35, 10751]                en   \n",
       "tt0113497                    NaN      [12, 14, 10751]                en   \n",
       "tt0113228               119050.0          [10749, 35]                en   \n",
       "tt0114885                    NaN      [35, 18, 10749]                en   \n",
       "tt0113041                96871.0                 [35]                en   \n",
       "tt0113277                    NaN     [28, 80, 18, 53]                en   \n",
       "tt0114319                    NaN          [35, 10749]                en   \n",
       "tt0112302                    NaN  [28, 12, 18, 10751]                en   \n",
       "tt0114576                    NaN         [28, 12, 53]                en   \n",
       "tt0113189                  645.0         [12, 28, 53]                en   \n",
       "\n",
       "                                                    overview  \\\n",
       "imdb_id                                                        \n",
       "tt0114709  Led by Woody, Andy's toys live happily in his ...   \n",
       "tt0113497  When siblings Judy and Peter discover an encha...   \n",
       "tt0113228  A family wedding reignites the ancient feud be...   \n",
       "tt0114885  Cheated on, mistreated and stepped on, the wom...   \n",
       "tt0113041  Just when George Banks has recovered from his ...   \n",
       "tt0113277  Obsessive master thief, Neil McCauley leads a ...   \n",
       "tt0114319  An ugly duckling having undergone a remarkable...   \n",
       "tt0112302  A mischievous young boy, Tom Sawyer, witnesses...   \n",
       "tt0114576  International action superstar Jean Claude Van...   \n",
       "tt0113189  James Bond must unmask the mysterious head of ...   \n",
       "\n",
       "          production_countries release_date  runtime    spoken_languages  \\\n",
       "imdb_id                                                                    \n",
       "tt0114709               ['US']   1995-10-30     81.0              ['en']   \n",
       "tt0113497               ['US']   1995-12-15    104.0        ['en', 'fr']   \n",
       "tt0113228               ['US']   1995-12-22    101.0              ['en']   \n",
       "tt0114885               ['US']   1995-12-22    127.0              ['en']   \n",
       "tt0113041               ['US']   1995-02-10    106.0              ['en']   \n",
       "tt0113277               ['US']   1995-12-15    170.0        ['en', 'es']   \n",
       "tt0114319         ['DE', 'US']   1995-12-15    127.0        ['fr', 'en']   \n",
       "tt0112302               ['US']   1995-12-22     97.0        ['en', 'de']   \n",
       "tt0114576               ['US']   1995-12-22    106.0              ['en']   \n",
       "tt0113189         ['GB', 'US']   1995-11-16    130.0  ['en', 'ru', 'es']   \n",
       "\n",
       "                                 title  Netflix  Hulu  Prime Video  Disney+  \n",
       "imdb_id                                                                      \n",
       "tt0114709                    Toy Story      NaN   NaN          NaN      NaN  \n",
       "tt0113497                      Jumanji      NaN   NaN          NaN      NaN  \n",
       "tt0113228             Grumpier Old Men      NaN   NaN          NaN      NaN  \n",
       "tt0114885            Waiting to Exhale      NaN   NaN          NaN      NaN  \n",
       "tt0113041  Father of the Bride Part II      NaN   NaN          NaN      NaN  \n",
       "tt0113277                         Heat      NaN   NaN          NaN      NaN  \n",
       "tt0114319                      Sabrina      NaN   NaN          NaN      NaN  \n",
       "tt0112302                 Tom and Huck      0.0   0.0          0.0      1.0  \n",
       "tt0114576                 Sudden Death      NaN   NaN          NaN      NaN  \n",
       "tt0113189                    GoldenEye      NaN   NaN          NaN      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"imdb_id\", inplace=True)\n",
    "print(df.info())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"release_date\"] = pd.to_numeric(pd.to_datetime(df[\"release_date\"]))\n",
    "df.fillna({ \"belongs_to_collection\": -1 }, inplace=True)\n",
    "df[\"belongs_to_collection\"] = df[\"belongs_to_collection\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Attributes =====\n",
      "Numerical:  ['release_date', 'runtime']\n",
      "Single Categorical:  ['belongs_to_collection', 'original_language']\n",
      "Multi-valued Categorical:  ['genres', 'production_countries', 'spoken_languages']\n",
      "Paragraph:  ['overview', 'title']\n"
     ]
    }
   ],
   "source": [
    "streaming_services = [\"Netflix\", \"Hulu\", \"Prime Video\", \"Disney+\"]\n",
    "\n",
    "num_attribs = df.drop(columns=streaming_services).select_dtypes(include='number').columns.to_list()\n",
    "cat_attribs = [\"belongs_to_collection\", \"original_language\"]\n",
    "multi_cat_attribs = [\"genres\", \"production_countries\", \"spoken_languages\"]\n",
    "paragraph_attribs = [\"overview\", \"title\"]\n",
    "\n",
    "print(\"===== Attributes =====\")\n",
    "print(\"Numerical: \", num_attribs)\n",
    "print(\"Single Categorical: \", cat_attribs)\n",
    "print(\"Multi-valued Categorical: \", multi_cat_attribs)\n",
    "print(\"Paragraph: \", paragraph_attribs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several entries where the overview is not null but are in whitespaces only, as shown below. Dropping them is necessary for the TfIdfVectorizer step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_id\n",
      "tt0212517     \n",
      "tt0098347     \n",
      "tt0094076     \n",
      "tt1309409     \n",
      "tt0034886     \n",
      "Name: overview, dtype: object results: (5,)\n",
      "Series([], Name: title, dtype: object) results: (0,)\n"
     ]
    }
   ],
   "source": [
    "for cat in paragraph_attribs:\n",
    "    res = (df.loc[df[cat].str.isspace()])[cat]\n",
    "    print(f\"{res} results: {res.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: overview, dtype: object) results: (0,)\n",
      "Series([], Name: title, dtype: object) results: (0,)\n"
     ]
    }
   ],
   "source": [
    "df.drop(df.loc[df[\"overview\"].str.isspace()].index, inplace=True)\n",
    "for cat in paragraph_attribs:\n",
    "    res = (df.loc[df[cat].str.isspace()])[cat]\n",
    "    print(f\"{res} results: {res.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting by streaming services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Shapes =====\n",
      "All:  (44408, 9)\n",
      "Netflix:  (600, 9)\n",
      "Hulu:  (310, 9)\n",
      "Prime:  (1062, 9)\n",
      "Disney+:  (315, 9)\n"
     ]
    }
   ],
   "source": [
    "all_df = df.drop(columns=streaming_services)\n",
    "netflix_df = df[df[\"Netflix\"] == 1].drop(columns=streaming_services)\n",
    "hulu_df = df[df[\"Hulu\"] == 1].drop(columns=streaming_services)\n",
    "prime_df = df[df[\"Prime Video\"] == 1].drop(columns=streaming_services)\n",
    "disney_df = df[df[\"Disney+\"] == 1].drop(columns=streaming_services)\n",
    "\n",
    "print(\"===== Dataset Shapes =====\")\n",
    "print(\"All: \", all_df.shape)\n",
    "print(\"Netflix: \", netflix_df.shape)\n",
    "print(\"Hulu: \", hulu_df.shape)\n",
    "print(\"Prime: \", prime_df.shape)\n",
    "print(\"Disney+: \", disney_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeSelector(BaseEstimator):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassEncoder(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlb = CountVectorizer(analyzer=set)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.T\n",
    "        res = []\n",
    "        for col in X:\n",
    "            res.append(self.mlb.fit_transform(col).toarray())\n",
    "        X = np.hstack(res)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce dimensionality (and save memory usage), frequency constraints were put in place for the TfIdfVectorizer.\n",
    "- Filtering out stop words (e.g. \"and\", \"is\", \"to\") is a necessary step. However, the stop words collection provided by sklearn is known to produce inconsistent results, and tend to cut out more than is necessary, therefore it was not used. Instead, a max_df constraint was put in place to filter out words that appear in more than 80% of the strings.\n",
    "- To remove words that are not likely to create matches between strings, a min_df constraint was put in place to filter out the words that appear in less than 2.5% of the strings.\n",
    "\n",
    "Additionally, since it is not uncommon for movie titles to use punctuations in unconventional ways (e.g. for acronyms, playful censoring, dash for subtitles), a custom tokenizer was defined to allow for more flexibility in punctuation removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotVectorizer(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tfidf = TfidfVectorizer(stop_words=None, tokenizer=self.tokenizer, max_df=0.8, min_df=0.025)\n",
    "\n",
    "    # Need to define our own tokenizer to allow for special cases (e.g. \"I.Q.\")\n",
    "    def tokenizer(self, text):\n",
    "        return text.translate(string.punctuation).split(\" \")\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.T\n",
    "        res = []\n",
    "        for col in X:\n",
    "            res.append(self.tfidf.fit_transform(col).toarray())\n",
    "        X = np.hstack(res)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('selector', AttributeSelector(num_attribs)),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    ('selector', AttributeSelector(cat_attribs)),\n",
    "    ('one_hot', OneHotEncoder(min_frequency=0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cat_pipeline = Pipeline([\n",
    "    ('selector', AttributeSelector(multi_cat_attribs)),\n",
    "    ('mlb', MultiClassEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_pipeline = Pipeline([\n",
    "    ('selector', AttributeSelector(paragraph_attribs)),\n",
    "    ('plot_vectorize', PlotVectorizer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparation_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline),\n",
    "    ('cat_pipeline', cat_pipeline),\n",
    "    ('multi_cat_pipeline', multi_cat_pipeline),\n",
    "    ('paragraph_pipeline', paragraph_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wlluk/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All integrated <class 'scipy.sparse._csr.csr_matrix'> (44408, 267)\n",
      "Netflix <class 'scipy.sparse._csr.csr_matrix'> (600, 272)\n",
      "Hulu <class 'scipy.sparse._csr.csr_matrix'> (310, 271)\n",
      "Prime Video <class 'scipy.sparse._csr.csr_matrix'> (1062, 262)\n",
      "Disney+ <class 'scipy.sparse._csr.csr_matrix'> (315, 288)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wlluk/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/wlluk/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/wlluk/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/wlluk/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "all_prepared = preparation_pipeline.fit_transform(all_df)\n",
    "netflix_prepared = preparation_pipeline.fit_transform(netflix_df)\n",
    "hulu_prepared = preparation_pipeline.fit_transform(hulu_df)\n",
    "prime_prepared = preparation_pipeline.fit_transform(prime_df)\n",
    "disney_prepared = preparation_pipeline.fit_transform(disney_df)\n",
    "\n",
    "print(\"All integrated\", type(all_prepared), all_prepared.shape)\n",
    "print(\"Netflix\", type(netflix_prepared), netflix_prepared.shape)\n",
    "print(\"Hulu\", type(hulu_prepared), hulu_prepared.shape)\n",
    "print(\"Prime Video\", type(prime_prepared), prime_prepared.shape)\n",
    "print(\"Disney+\", type(disney_prepared), disney_prepared.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_df(data, original_df):\n",
    "    index = original_df.index\n",
    "    new_df = pd.DataFrame.sparse.from_spmatrix(data)\n",
    "    return new_df.set_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tt0114709</th>\n",
       "      <td>0.146503</td>\n",
       "      <td>-0.374551</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113497</th>\n",
       "      <td>0.151723</td>\n",
       "      <td>0.238843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113228</th>\n",
       "      <td>0.152517</td>\n",
       "      <td>0.158835</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0114885</th>\n",
       "      <td>0.152517</td>\n",
       "      <td>0.852238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113041</th>\n",
       "      <td>0.116773</td>\n",
       "      <td>0.292182</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.824769</td>\n",
       "      <td>0.565469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113277</th>\n",
       "      <td>0.151723</td>\n",
       "      <td>1.999019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0114319</th>\n",
       "      <td>0.151723</td>\n",
       "      <td>0.852238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0112302</th>\n",
       "      <td>0.152517</td>\n",
       "      <td>0.052158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.184734</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0114576</th>\n",
       "      <td>0.152517</td>\n",
       "      <td>0.292182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113189</th>\n",
       "      <td>0.148432</td>\n",
       "      <td>0.932246</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1    2    3    4    5    6    7    8    9    ...  \\\n",
       "imdb_id                                                                ...   \n",
       "tt0114709  0.146503 -0.374551    0  1.0    0  1.0    0    0    0    0  ...   \n",
       "tt0113497  0.151723  0.238843  1.0    0    0  1.0    0    0    0    0  ...   \n",
       "tt0113228  0.152517  0.158835    0  1.0    0  1.0    0    0    0    0  ...   \n",
       "tt0114885  0.152517  0.852238  1.0    0    0  1.0    0    0    0    0  ...   \n",
       "tt0113041  0.116773  0.292182    0  1.0    0  1.0    0    0    0    0  ...   \n",
       "tt0113277  0.151723  1.999019  1.0    0    0  1.0    0    0    0    0  ...   \n",
       "tt0114319  0.151723  0.852238  1.0    0    0  1.0    0    0    0    0  ...   \n",
       "tt0112302  0.152517  0.052158  1.0    0    0  1.0    0    0    0    0  ...   \n",
       "tt0114576  0.152517  0.292182  1.0    0    0  1.0    0    0    0    0  ...   \n",
       "tt0113189  0.148432  0.932246    0  1.0    0  1.0    0    0    0    0  ...   \n",
       "\n",
       "           257  258  259      260       261  262  263  264       265       266  \n",
       "imdb_id                                                                         \n",
       "tt0114709    0    0    0        0         0    0    0    0         0         0  \n",
       "tt0113497    0    0    0  0.25156         0    0    0    0         0         0  \n",
       "tt0113228    0    0    0        0         0    0    0    0         0         0  \n",
       "tt0114885    0    0    0        0         0    0    0    0         0         0  \n",
       "tt0113041    0    0    0        0         0    0    0    0  0.824769  0.565469  \n",
       "tt0113277    0    0    0        0         0    0    0    0         0         0  \n",
       "tt0114319    0    0    0        0         0    0    0    0         0         0  \n",
       "tt0112302    0    0    0        0  0.184734    0  1.0    0         0         0  \n",
       "tt0114576    0    0    0        0         0    0    0    0         0         0  \n",
       "tt0113189    0    0    0        0         0    0    0    0         0         0  \n",
       "\n",
       "[10 rows x 267 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_prepared_df = wrap_df(all_prepared, all_df)\n",
    "netflix_prepared_df = wrap_df(netflix_prepared, netflix_df)\n",
    "hulu_prepared_df = wrap_df(hulu_prepared, hulu_df)\n",
    "prime_prepared_df = wrap_df(prime_prepared, prime_df)\n",
    "disney_prepared_df = wrap_df(disney_prepared, disney_df)\n",
    "\n",
    "\n",
    "all_prepared_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(BaseEstimator):\n",
    "    def __init__(self, norm = cosine_similarity, num_recommendations = 10):\n",
    "        super().__init__()\n",
    "        self.norm = norm\n",
    "        self.num_recommendations = num_recommendations\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        index = X.index\n",
    "        self.kernel = pd.DataFrame(self.norm(X, X), index=index, columns=index)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        #? Need to test multiple values\n",
    "        sim_scores = self.kernel.loc[X.index.to_list()]\n",
    "        print(sim_scores)\n",
    "        sim_scores = sorted(sim_scores, key=lambda e: e[1], reverse=True)\n",
    "        return sim_scores[1:self.num_recommendations + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Distance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"cosine_similarity\": cosine_similarity}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics.items():\n",
    "    predictions = Recommender(metric[1]).fit(all_prepared_df)\n",
    "    #? Need to test\n",
    "    # average_similarity_score = sum(predictions) / len(predictions)\n",
    "    # print(f\"Average {metric[0]}: {average_similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspection, we choose {{}} as our distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = cosine_similarity\n",
    "#! Need change"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
