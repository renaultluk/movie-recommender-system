{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataframe\n",
    "##### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>title</th>\n",
       "      <th>Netflix</th>\n",
       "      <th>Hulu</th>\n",
       "      <th>Prime Video</th>\n",
       "      <th>Disney+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10194.0</td>\n",
       "      <td>[16, 35, 10751]</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>81.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[12, 14, 10751]</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>104.0</td>\n",
       "      <td>['en', 'fr']</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119050.0</td>\n",
       "      <td>[10749, 35]</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>101.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 18, 10749]</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>127.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96871.0</td>\n",
       "      <td>[35]</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>106.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 80, 18, 53]</td>\n",
       "      <td>tt0113277</td>\n",
       "      <td>en</td>\n",
       "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>170.0</td>\n",
       "      <td>['en', 'es']</td>\n",
       "      <td>Heat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 10749]</td>\n",
       "      <td>tt0114319</td>\n",
       "      <td>en</td>\n",
       "      <td>An ugly duckling having undergone a remarkable...</td>\n",
       "      <td>['DE', 'US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>127.0</td>\n",
       "      <td>['fr', 'en']</td>\n",
       "      <td>Sabrina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 12, 18, 10751]</td>\n",
       "      <td>tt0112302</td>\n",
       "      <td>en</td>\n",
       "      <td>A mischievous young boy, Tom Sawyer, witnesses...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>97.0</td>\n",
       "      <td>['en', 'de']</td>\n",
       "      <td>Tom and Huck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 12, 53]</td>\n",
       "      <td>tt0114576</td>\n",
       "      <td>en</td>\n",
       "      <td>International action superstar Jean Claude Van...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>106.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Sudden Death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>645.0</td>\n",
       "      <td>[12, 28, 53]</td>\n",
       "      <td>tt0113189</td>\n",
       "      <td>en</td>\n",
       "      <td>James Bond must unmask the mysterious head of ...</td>\n",
       "      <td>['GB', 'US']</td>\n",
       "      <td>1995-11-16</td>\n",
       "      <td>130.0</td>\n",
       "      <td>['en', 'ru', 'es']</td>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   belongs_to_collection               genres    imdb_id original_language  \\\n",
       "0                10194.0      [16, 35, 10751]  tt0114709                en   \n",
       "1                    NaN      [12, 14, 10751]  tt0113497                en   \n",
       "2               119050.0          [10749, 35]  tt0113228                en   \n",
       "3                    NaN      [35, 18, 10749]  tt0114885                en   \n",
       "4                96871.0                 [35]  tt0113041                en   \n",
       "5                    NaN     [28, 80, 18, 53]  tt0113277                en   \n",
       "6                    NaN          [35, 10749]  tt0114319                en   \n",
       "7                    NaN  [28, 12, 18, 10751]  tt0112302                en   \n",
       "8                    NaN         [28, 12, 53]  tt0114576                en   \n",
       "9                  645.0         [12, 28, 53]  tt0113189                en   \n",
       "\n",
       "                                            overview production_countries  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...               ['US']   \n",
       "1  When siblings Judy and Peter discover an encha...               ['US']   \n",
       "2  A family wedding reignites the ancient feud be...               ['US']   \n",
       "3  Cheated on, mistreated and stepped on, the wom...               ['US']   \n",
       "4  Just when George Banks has recovered from his ...               ['US']   \n",
       "5  Obsessive master thief, Neil McCauley leads a ...               ['US']   \n",
       "6  An ugly duckling having undergone a remarkable...         ['DE', 'US']   \n",
       "7  A mischievous young boy, Tom Sawyer, witnesses...               ['US']   \n",
       "8  International action superstar Jean Claude Van...               ['US']   \n",
       "9  James Bond must unmask the mysterious head of ...         ['GB', 'US']   \n",
       "\n",
       "  release_date  runtime    spoken_languages                        title  \\\n",
       "0   1995-10-30     81.0              ['en']                    Toy Story   \n",
       "1   1995-12-15    104.0        ['en', 'fr']                      Jumanji   \n",
       "2   1995-12-22    101.0              ['en']             Grumpier Old Men   \n",
       "3   1995-12-22    127.0              ['en']            Waiting to Exhale   \n",
       "4   1995-02-10    106.0              ['en']  Father of the Bride Part II   \n",
       "5   1995-12-15    170.0        ['en', 'es']                         Heat   \n",
       "6   1995-12-15    127.0        ['fr', 'en']                      Sabrina   \n",
       "7   1995-12-22     97.0        ['en', 'de']                 Tom and Huck   \n",
       "8   1995-12-22    106.0              ['en']                 Sudden Death   \n",
       "9   1995-11-16    130.0  ['en', 'ru', 'es']                    GoldenEye   \n",
       "\n",
       "   Netflix  Hulu  Prime Video  Disney+  \n",
       "0      NaN   NaN          NaN      NaN  \n",
       "1      NaN   NaN          NaN      NaN  \n",
       "2      NaN   NaN          NaN      NaN  \n",
       "3      NaN   NaN          NaN      NaN  \n",
       "4      NaN   NaN          NaN      NaN  \n",
       "5      NaN   NaN          NaN      NaN  \n",
       "6      NaN   NaN          NaN      NaN  \n",
       "7      0.0   0.0          0.0      1.0  \n",
       "8      NaN   NaN          NaN      NaN  \n",
       "9      NaN   NaN          NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"meta_clean.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 44413 entries, tt0114709 to tt6980792\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   belongs_to_collection  4427 non-null   float64\n",
      " 1   genres                 44413 non-null  object \n",
      " 2   original_language      44413 non-null  object \n",
      " 3   overview               44413 non-null  object \n",
      " 4   production_countries   44413 non-null  object \n",
      " 5   release_date           44413 non-null  object \n",
      " 6   runtime                44413 non-null  float64\n",
      " 7   spoken_languages       44413 non-null  object \n",
      " 8   title                  44413 non-null  object \n",
      " 9   Netflix                2205 non-null   float64\n",
      " 10  Hulu                   2205 non-null   float64\n",
      " 11  Prime Video            2205 non-null   float64\n",
      " 12  Disney+                2205 non-null   float64\n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 4.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>genres</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>title</th>\n",
       "      <th>Netflix</th>\n",
       "      <th>Hulu</th>\n",
       "      <th>Prime Video</th>\n",
       "      <th>Disney+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tt0114709</th>\n",
       "      <td>10194.0</td>\n",
       "      <td>[16, 35, 10751]</td>\n",
       "      <td>en</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>81.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113497</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[12, 14, 10751]</td>\n",
       "      <td>en</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>104.0</td>\n",
       "      <td>['en', 'fr']</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113228</th>\n",
       "      <td>119050.0</td>\n",
       "      <td>[10749, 35]</td>\n",
       "      <td>en</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>101.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0114885</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 18, 10749]</td>\n",
       "      <td>en</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>127.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113041</th>\n",
       "      <td>96871.0</td>\n",
       "      <td>[35]</td>\n",
       "      <td>en</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>106.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113277</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 80, 18, 53]</td>\n",
       "      <td>en</td>\n",
       "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>170.0</td>\n",
       "      <td>['en', 'es']</td>\n",
       "      <td>Heat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0114319</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 10749]</td>\n",
       "      <td>en</td>\n",
       "      <td>An ugly duckling having undergone a remarkable...</td>\n",
       "      <td>['DE', 'US']</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>127.0</td>\n",
       "      <td>['fr', 'en']</td>\n",
       "      <td>Sabrina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0112302</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 12, 18, 10751]</td>\n",
       "      <td>en</td>\n",
       "      <td>A mischievous young boy, Tom Sawyer, witnesses...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>97.0</td>\n",
       "      <td>['en', 'de']</td>\n",
       "      <td>Tom and Huck</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0114576</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[28, 12, 53]</td>\n",
       "      <td>en</td>\n",
       "      <td>International action superstar Jean Claude Van...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>106.0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>Sudden Death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tt0113189</th>\n",
       "      <td>645.0</td>\n",
       "      <td>[12, 28, 53]</td>\n",
       "      <td>en</td>\n",
       "      <td>James Bond must unmask the mysterious head of ...</td>\n",
       "      <td>['GB', 'US']</td>\n",
       "      <td>1995-11-16</td>\n",
       "      <td>130.0</td>\n",
       "      <td>['en', 'ru', 'es']</td>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           belongs_to_collection               genres original_language  \\\n",
       "imdb_id                                                                   \n",
       "tt0114709                10194.0      [16, 35, 10751]                en   \n",
       "tt0113497                    NaN      [12, 14, 10751]                en   \n",
       "tt0113228               119050.0          [10749, 35]                en   \n",
       "tt0114885                    NaN      [35, 18, 10749]                en   \n",
       "tt0113041                96871.0                 [35]                en   \n",
       "tt0113277                    NaN     [28, 80, 18, 53]                en   \n",
       "tt0114319                    NaN          [35, 10749]                en   \n",
       "tt0112302                    NaN  [28, 12, 18, 10751]                en   \n",
       "tt0114576                    NaN         [28, 12, 53]                en   \n",
       "tt0113189                  645.0         [12, 28, 53]                en   \n",
       "\n",
       "                                                    overview  \\\n",
       "imdb_id                                                        \n",
       "tt0114709  Led by Woody, Andy's toys live happily in his ...   \n",
       "tt0113497  When siblings Judy and Peter discover an encha...   \n",
       "tt0113228  A family wedding reignites the ancient feud be...   \n",
       "tt0114885  Cheated on, mistreated and stepped on, the wom...   \n",
       "tt0113041  Just when George Banks has recovered from his ...   \n",
       "tt0113277  Obsessive master thief, Neil McCauley leads a ...   \n",
       "tt0114319  An ugly duckling having undergone a remarkable...   \n",
       "tt0112302  A mischievous young boy, Tom Sawyer, witnesses...   \n",
       "tt0114576  International action superstar Jean Claude Van...   \n",
       "tt0113189  James Bond must unmask the mysterious head of ...   \n",
       "\n",
       "          production_countries release_date  runtime    spoken_languages  \\\n",
       "imdb_id                                                                    \n",
       "tt0114709               ['US']   1995-10-30     81.0              ['en']   \n",
       "tt0113497               ['US']   1995-12-15    104.0        ['en', 'fr']   \n",
       "tt0113228               ['US']   1995-12-22    101.0              ['en']   \n",
       "tt0114885               ['US']   1995-12-22    127.0              ['en']   \n",
       "tt0113041               ['US']   1995-02-10    106.0              ['en']   \n",
       "tt0113277               ['US']   1995-12-15    170.0        ['en', 'es']   \n",
       "tt0114319         ['DE', 'US']   1995-12-15    127.0        ['fr', 'en']   \n",
       "tt0112302               ['US']   1995-12-22     97.0        ['en', 'de']   \n",
       "tt0114576               ['US']   1995-12-22    106.0              ['en']   \n",
       "tt0113189         ['GB', 'US']   1995-11-16    130.0  ['en', 'ru', 'es']   \n",
       "\n",
       "                                 title  Netflix  Hulu  Prime Video  Disney+  \n",
       "imdb_id                                                                      \n",
       "tt0114709                    Toy Story      NaN   NaN          NaN      NaN  \n",
       "tt0113497                      Jumanji      NaN   NaN          NaN      NaN  \n",
       "tt0113228             Grumpier Old Men      NaN   NaN          NaN      NaN  \n",
       "tt0114885            Waiting to Exhale      NaN   NaN          NaN      NaN  \n",
       "tt0113041  Father of the Bride Part II      NaN   NaN          NaN      NaN  \n",
       "tt0113277                         Heat      NaN   NaN          NaN      NaN  \n",
       "tt0114319                      Sabrina      NaN   NaN          NaN      NaN  \n",
       "tt0112302                 Tom and Huck      0.0   0.0          0.0      1.0  \n",
       "tt0114576                 Sudden Death      NaN   NaN          NaN      NaN  \n",
       "tt0113189                    GoldenEye      NaN   NaN          NaN      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"imdb_id\", inplace=True)\n",
    "print(df.info())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"release_date\"] = pd.to_numeric(pd.to_datetime(df[\"release_date\"]))\n",
    "df.fillna({ \"belongs_to_collection\": -1 }, inplace=True)\n",
    "df[\"belongs_to_collection\"] = df[\"belongs_to_collection\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Attributes =====\n",
      "Numerical:  ['release_date', 'runtime']\n",
      "Single Categorical:  ['belongs_to_collection', 'original_language']\n",
      "Multi-valued Categorical:  ['genres', 'production_countries', 'spoken_languages']\n",
      "Paragraph:  ['overview', 'title']\n"
     ]
    }
   ],
   "source": [
    "streaming_services = [\"Netflix\", \"Hulu\", \"Prime Video\", \"Disney+\"]\n",
    "\n",
    "num_attribs = df.drop(columns=streaming_services).select_dtypes(include='number').columns.to_list()\n",
    "cat_attribs = [\"belongs_to_collection\", \"original_language\"]\n",
    "multi_cat_attribs = [\"genres\", \"production_countries\", \"spoken_languages\"]\n",
    "paragraph_attribs = [\"overview\", \"title\"]\n",
    "\n",
    "print(\"===== Attributes =====\")\n",
    "print(\"Numerical: \", num_attribs)\n",
    "print(\"Single Categorical: \", cat_attribs)\n",
    "print(\"Multi-valued Categorical: \", multi_cat_attribs)\n",
    "print(\"Paragraph: \", paragraph_attribs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several entries where the overview is not null but are in whitespaces only, as shown below. Dropping them is necessary for the TfIdfVectorizer step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_id\n",
      "tt0212517     \n",
      "tt0098347     \n",
      "tt0094076     \n",
      "tt1309409     \n",
      "tt0034886     \n",
      "Name: overview, dtype: object results: (5,)\n",
      "Series([], Name: title, dtype: object) results: (0,)\n"
     ]
    }
   ],
   "source": [
    "for cat in paragraph_attribs:\n",
    "    res = (df.loc[df[cat].str.isspace()])[cat]\n",
    "    print(f\"{res} results: {res.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: overview, dtype: object) results: (0,)\n",
      "Series([], Name: title, dtype: object) results: (0,)\n"
     ]
    }
   ],
   "source": [
    "df.drop(df.loc[df[\"overview\"].str.isspace()].index, inplace=True)\n",
    "for cat in paragraph_attribs:\n",
    "    res = (df.loc[df[cat].str.isspace()])[cat]\n",
    "    print(f\"{res} results: {res.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting by streaming services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Shapes =====\n",
      "All:  (44408, 9)\n",
      "Netflix:  (600, 9)\n",
      "Hulu:  (310, 9)\n",
      "Prime:  (1062, 9)\n",
      "Disney+:  (315, 9)\n"
     ]
    }
   ],
   "source": [
    "all_df = df.drop(columns=streaming_services)\n",
    "netflix_df = df[df[\"Netflix\"] == 1].drop(columns=streaming_services)\n",
    "hulu_df = df[df[\"Hulu\"] == 1].drop(columns=streaming_services)\n",
    "prime_df = df[df[\"Prime Video\"] == 1].drop(columns=streaming_services)\n",
    "disney_df = df[df[\"Disney+\"] == 1].drop(columns=streaming_services)\n",
    "\n",
    "print(\"===== Dataset Shapes =====\")\n",
    "print(\"All: \", all_df.shape)\n",
    "print(\"Netflix: \", netflix_df.shape)\n",
    "print(\"Hulu: \", hulu_df.shape)\n",
    "print(\"Prime: \", prime_df.shape)\n",
    "print(\"Disney+: \", disney_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeSelector(BaseEstimator):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassEncoder(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mlb = CountVectorizer(analyzer=set)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.T\n",
    "        res = []\n",
    "        for col in X:\n",
    "            res.append(self.mlb.fit_transform(col).toarray())\n",
    "        X = np.hstack(res)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce dimensionality (and save memory usage), frequency constraints were put in place for the TfIdfVectorizer.\n",
    "- Filtering out stop words (e.g. \"and\", \"is\", \"to\") is a necessary step. However, the stop words collection provided by sklearn is known to produce inconsistent results, and tend to cut out more than is necessary, therefore it was not used. Instead, a max_df constraint was put in place to filter out words that appear in more than 80% of the strings.\n",
    "- To remove words that are not likely to create matches between strings, a min_df constraint was put in place to filter out the words that appear in less than 2.5% of the strings.\n",
    "\n",
    "Additionally, since it is not uncommon for movie titles to use punctuations in unconventional ways (e.g. for acronyms, playful censoring, dash for subtitles), a custom tokenizer was defined to allow for more flexibility in punctuation removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotVectorizer(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tfidf = TfidfVectorizer(stop_words=None, tokenizer=self.tokenizer, max_df=0.8, min_df=0.025)\n",
    "\n",
    "    # Need to define our own tokenizer to allow for special cases (e.g. \"I.Q.\")\n",
    "    def tokenizer(self, text):\n",
    "        return text.translate(string.punctuation).split(\" \")\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.T\n",
    "        res = []\n",
    "        for col in X:\n",
    "            res.append(self.tfidf.fit_transform(col).toarray())\n",
    "        X = np.hstack(res)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('selector', AttributeSelector(num_attribs)),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "    ('selector', AttributeSelector(cat_attribs)),\n",
    "    ('one_hot', OneHotEncoder(min_frequency=0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cat_pipeline = Pipeline([\n",
    "    ('selector', AttributeSelector(multi_cat_attribs)),\n",
    "    ('mlb', MultiClassEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_pipeline = Pipeline([\n",
    "    ('selector', AttributeSelector(paragraph_attribs)),\n",
    "    ('plot_vectorize', PlotVectorizer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparation_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline', num_pipeline),\n",
    "    ('cat_pipeline', cat_pipeline),\n",
    "    ('multi_cat_pipeline', multi_cat_pipeline),\n",
    "    ('paragraph_pipeline', paragraph_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All integrated <class 'scipy.sparse._csr.csr_matrix'> (44408, 267)\n",
      "Netflix <class 'scipy.sparse._csr.csr_matrix'> (600, 272)\n",
      "Hulu <class 'scipy.sparse._csr.csr_matrix'> (310, 271)\n",
      "Prime Video <class 'scipy.sparse._csr.csr_matrix'> (1062, 262)\n",
      "Disney+ <class 'scipy.sparse._csr.csr_matrix'> (315, 288)\n"
     ]
    }
   ],
   "source": [
    "all_prepared = preparation_pipeline.fit_transform(all_df)\n",
    "netflix_prepared = preparation_pipeline.fit_transform(netflix_df)\n",
    "hulu_prepared = preparation_pipeline.fit_transform(hulu_df)\n",
    "prime_prepared = preparation_pipeline.fit_transform(prime_df)\n",
    "disney_prepared = preparation_pipeline.fit_transform(disney_df)\n",
    "\n",
    "print(\"All integrated\", type(all_prepared), all_prepared.shape)\n",
    "print(\"Netflix\", type(netflix_prepared), netflix_prepared.shape)\n",
    "print(\"Hulu\", type(hulu_prepared), hulu_prepared.shape)\n",
    "print(\"Prime Video\", type(prime_prepared), prime_prepared.shape)\n",
    "print(\"Disney+\", type(disney_prepared), disney_prepared.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(BaseEstimator):\n",
    "    def __init__(self, norm = cosine_similarity, num_recommendations = 10):\n",
    "        super().__init__()\n",
    "        self.norm = norm\n",
    "        self.num_recommendations = num_recommendations\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.kernel = self.norm(X, X)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        #? Need to test multiple values\n",
    "        sim_scores = list(enumerate(self.kernel[X]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda e: e[1], reverse=True)\n",
    "        return sim_scores[1:self.num_recommendations + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Distance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"cosine_similarity\": cosine_similarity}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.7 GiB for an array with shape (44408, 44408) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 2\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m Recommender(metric[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mfit(all_prepared)\u001b[38;5;241m.\u001b[39mpredict(all_prepared)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#? Need to test\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     average_similarity_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(predictions) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(predictions)\n",
      "Cell \u001b[1;32mIn[19], line 8\u001b[0m, in \u001b[0;36mRecommender.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(X, X)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1665\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1663\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1665\u001b[0m K \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X_normalized, Y_normalized\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39mdense_output)\n\u001b[0;32m   1667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:216\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    208\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    211\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    215\u001b[0m ):\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1106\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1106\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_toarray_args(order, out)\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:1327\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 14.7 GiB for an array with shape (44408, 44408) and data type float64"
     ]
    }
   ],
   "source": [
    "for metric in metrics.items():\n",
    "    predictions = Recommender(metric[1]).fit(all_prepared).predict(all_prepared)\n",
    "    #? Need to test\n",
    "    average_similarity_score = sum(predictions) / len(predictions)\n",
    "    print(f\"Average {metric[0]}: {average_similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspection, we choose {{}} as our distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = cosine_similarity\n",
    "#! Need change"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
